{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf38f60",
   "metadata": {},
   "source": [
    "# Objective\n",
    "<ol>\n",
    "<li>Importing libraries</li>\n",
    "<li>Importing dataset</li>\n",
    "<li>Handling Duplicate Values</li>\n",
    "<li>Handling Missing values</li>\n",
    "<li>Encoding Categorical data</li>\n",
    "<li>Feature Scaling</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34da7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35222135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country   Age   Salary Purchased\n",
      "0    France  44.0  72000.0        No\n",
      "1     Spain  27.0  48000.0       Yes\n",
      "2   Germany  30.0  54000.0        No\n",
      "3     Spain  38.0  61000.0        No\n",
      "4   Nigeria  18.0  15000.0        No\n",
      "5   Germany  40.0      NaN       Yes\n",
      "6    France  35.0  58000.0       Yes\n",
      "7     Spain   NaN  52000.0        No\n",
      "8    France  48.0  79000.0       Yes\n",
      "9   Germany  50.0  83000.0        No\n",
      "10   France  37.0  67000.0       Yes\n",
      "11  Nigeria  50.0  60000.0       Yes\n",
      "12   France  22.0  30000.0        No\n",
      "13      NaN  44.0  45000.0       Yes\n",
      "14   France  47.0  78000.0       NaN\n",
      "15  Nigeria  35.0  43000.0       Yes\n",
      "16    Spain  34.0  44000.0       Yes\n",
      "17    Spain  27.0  48000.0       Yes\n",
      "18    Spain  33.0  48000.0       Yes\n",
      "19  Nigeria  29.0  77000.0       Yes\n",
      "20    Spain   NaN  57000.0       Yes\n",
      "21   France  44.0  48000.0       Yes\n",
      "22  Germany  50.0  83000.0        No\n",
      "23   France  37.0  67000.0       Yes\n",
      "24   France  37.0  23000.0       Yes\n",
      "25  Germany  45.0  50000.0        No\n",
      "26   France  37.0  67000.0       Yes\n",
      "27  Nigeria  30.0  30000.0       Yes\n",
      "28  Nigeria  29.0  15000.0        No\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "dataset = pd.read_csv('sample_data.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f495a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Nigeria  18.0  15000.0        No"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first few rows of the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b6b4903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.925926</td>\n",
       "      <td>53642.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.757089</td>\n",
       "      <td>19216.532785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>44750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>53000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>67000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age        Salary\n",
       "count  27.000000     28.000000\n",
       "mean   36.925926  53642.857143\n",
       "std     8.757089  19216.532785\n",
       "min    18.000000  15000.000000\n",
       "25%    30.000000  44750.000000\n",
       "50%    37.000000  53000.000000\n",
       "75%    44.000000  67000.000000\n",
       "max    50.000000  83000.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing statistical info about dataset\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9595551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country   Age   Salary Purchased\n",
      "0    France  44.0  72000.0        No\n",
      "1     Spain  27.0  48000.0       Yes\n",
      "2   Germany  30.0  54000.0        No\n",
      "3     Spain  38.0  61000.0        No\n",
      "4   Nigeria  18.0  15000.0        No\n",
      "5   Germany  40.0      NaN       Yes\n",
      "6    France  35.0  58000.0       Yes\n",
      "7     Spain   NaN  52000.0        No\n",
      "8    France  48.0  79000.0       Yes\n",
      "9   Germany  50.0  83000.0        No\n",
      "10   France  37.0  67000.0       Yes\n",
      "11  Nigeria  50.0  60000.0       Yes\n",
      "12   France  22.0  30000.0        No\n",
      "13      NaN  44.0  45000.0       Yes\n",
      "14   France  47.0  78000.0       NaN\n",
      "15  Nigeria  35.0  43000.0       Yes\n",
      "16    Spain  34.0  44000.0       Yes\n",
      "18    Spain  33.0  48000.0       Yes\n",
      "19  Nigeria  29.0  77000.0       Yes\n",
      "20    Spain   NaN  57000.0       Yes\n",
      "21   France  44.0  48000.0       Yes\n",
      "24   France  37.0  23000.0       Yes\n",
      "25  Germany  45.0  50000.0        No\n",
      "27  Nigeria  30.0  30000.0       Yes\n",
      "28  Nigeria  29.0  15000.0        No\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicate values\n",
    "dataset = dataset.drop_duplicates()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3388c7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.782609</td>\n",
       "      <td>51541.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.852101</td>\n",
       "      <td>19352.517344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>43750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>51000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>62500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age        Salary\n",
       "count  23.000000     24.000000\n",
       "mean   36.782609  51541.666667\n",
       "std     8.852101  19352.517344\n",
       "min    18.000000  15000.000000\n",
       "25%    30.000000  43750.000000\n",
       "50%    37.000000  51000.000000\n",
       "75%    44.000000  62500.000000\n",
       "max    50.000000  83000.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can run the .describe() method on our dataset to check if there are any changes\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed7745",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "In our dataset, there may be some missing values. We cannot train our model with a dataset that contains missing values. So we have to check if our dataset has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4120a252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country    Age  Salary  Purchased\n",
       "0     False  False   False      False\n",
       "1     False  False   False      False\n",
       "2     False  False   False      False\n",
       "3     False  False   False      False\n",
       "4     False  False   False      False\n",
       "5     False  False    True      False\n",
       "6     False  False   False      False\n",
       "7     False   True   False      False\n",
       "8     False  False   False      False\n",
       "9     False  False   False      False\n",
       "10    False  False   False      False\n",
       "11    False  False   False      False\n",
       "12    False  False   False      False\n",
       "13     True  False   False      False\n",
       "14    False  False   False       True\n",
       "15    False  False   False      False\n",
       "16    False  False   False      False\n",
       "18    False  False   False      False\n",
       "19    False  False   False      False\n",
       "20    False   True   False      False\n",
       "21    False  False   False      False\n",
       "24    False  False   False      False\n",
       "25    False  False   False      False\n",
       "27    False  False   False      False\n",
       "28    False  False   False      False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "dataset.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b12d94b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country      1\n",
       "Age          2\n",
       "Salary       1\n",
       "Purchased    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of missing data\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90026931",
   "metadata": {},
   "source": [
    "We can handle missing values by:\n",
    "\n",
    "Deleting the row/column: This is one of the easiest ways to handle missing values. If we have a lot of missing values in a column, we can just remove that column from our dataset. We could also delete any row with missing values. The only problem with this method is that we lose some information needed by our model to make accurate predictions.\n",
    "\n",
    "Replacing missing values with Mean/Mode/Median: For numerical data, we can replace missing values with the mean, mode, or median of the column with the missing value. This way we get to preserve some information needed by our model. The mean is mostly preferred.\n",
    "\n",
    "Replacing with values close to the missing value: We could also replace missing values with the value that comes before or after it in the same column.\n",
    "\n",
    "For the columns ‘Country’ and ‘Purchased’, I will remove the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f38cc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical data rows with missing values\n",
    "dataset.dropna(how='any', subset=['Country', 'Purchased'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e22d9b",
   "metadata": {},
   "source": [
    "Before I replace the missing values in the other columns, I will separate the independent variables and target variable. The target variable is what we are trying to predict. While the independent variables are the features that will help us make the predictions. The columns ‘Country’, ‘Age’, and ‘Salary’ are our independent variables, while ‘Purchased’ is our target variable.\n",
    "\n",
    "In the code above, for the parameter ‘how’, the argument ‘any’ drops the row if any value is null. But the argument ‘all’ will only drop the row if all the values are null. The argument for the ‘subset’ parameter is a list containing the columns we want to remove missing values from. ‘inplace=True’ modifies our original dataframe, instead of returning a copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fb74b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Nigeria' 18.0 15000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]\n",
      " ['Nigeria' 50.0 60000.0]\n",
      " ['France' 22.0 30000.0]\n",
      " ['Nigeria' 35.0 43000.0]\n",
      " ['Spain' 34.0 44000.0]\n",
      " ['Spain' 33.0 48000.0]\n",
      " ['Nigeria' 29.0 77000.0]\n",
      " ['Spain' nan 57000.0]\n",
      " ['France' 44.0 48000.0]\n",
      " ['France' 37.0 23000.0]\n",
      " ['Germany' 45.0 50000.0]\n",
      " ['Nigeria' 30.0 30000.0]\n",
      " ['Nigeria' 29.0 15000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into independent & dependent variable\n",
    "X = dataset[['Country', 'Age', 'Salary']].values\n",
    "y = dataset['Purchased'].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c771a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No'\n",
      " 'Yes' 'Yes' 'Yes' 'Yes' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a76f5",
   "metadata": {},
   "source": [
    "We will replace the missing values in the ‘Age’ and ‘Salary’ columns with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "560c0252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [18.0 15000.0]\n",
      " [40.0 nan]\n",
      " [35.0 58000.0]\n",
      " [nan 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]\n",
      " [50.0 60000.0]\n",
      " [22.0 30000.0]\n",
      " [35.0 43000.0]\n",
      " [34.0 44000.0]\n",
      " [33.0 48000.0]\n",
      " [29.0 77000.0]\n",
      " [nan 57000.0]\n",
      " [44.0 48000.0]\n",
      " [37.0 23000.0]\n",
      " [45.0 50000.0]\n",
      " [30.0 30000.0]\n",
      " [29.0 15000.0]]\n"
     ]
    }
   ],
   "source": [
    "# replacing the missing values in the age & salary column with the mean\n",
    "# import the SimpleImputer class from the sklearn library\n",
    "from sklearn.impute import SimpleImputer\n",
    "print(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb478b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [18.0 15000.0]\n",
      " [40.0 50636.36363636364]\n",
      " [35.0 58000.0]\n",
      " [35.95238095238095 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]\n",
      " [50.0 60000.0]\n",
      " [22.0 30000.0]\n",
      " [35.0 43000.0]\n",
      " [34.0 44000.0]\n",
      " [33.0 48000.0]\n",
      " [29.0 77000.0]\n",
      " [35.95238095238095 57000.0]\n",
      " [44.0 48000.0]\n",
      " [37.0 23000.0]\n",
      " [45.0 50000.0]\n",
      " [30.0 30000.0]\n",
      " [29.0 15000.0]]\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "print(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ae03c",
   "metadata": {},
   "source": [
    "In the SimpleImputer() class, np.nan represents the missing values in our NumPy array. That will be the argument to the ‘missing_values’ parameter. ‘strategy=mean’ means we will be replacing the missing values with the mean.\n",
    "\n",
    "The .fit() method will connect our ‘imputer’ object to the matrix of features X. But to do the replacement, we need to call another method, this is the .transform() method. This will apply the transformation, thereby replacing the missing values with the mean.\n",
    "\n",
    "Encoding Categorical Data\n",
    "Deborah Rumsey defines categorical data as the type of data that is used to group information with similar characteristics. In our dataset, the ‘Country’ & ‘Purchased’ columns contain categorical data.\n",
    "\n",
    "Our Machine Learning Model works with numbers, so our model won’t understand these categorical data. We need to encode these categorical data into numbers. To do this, we apply One-Hot Encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b85cd",
   "metadata": {},
   "source": [
    "From sklearn.compose, we will import the ColumnTransformer class. We will also import OneHotEncoder class from the preprocessing module of the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6965ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 0.0 18.0 15000.0]\n",
      " [0.0 1.0 0.0 0.0 40.0 50636.36363636364]\n",
      " [1.0 0.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 0.0 1.0 35.95238095238095 52000.0]\n",
      " [1.0 0.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 0.0 37.0 67000.0]\n",
      " [0.0 0.0 1.0 0.0 50.0 60000.0]\n",
      " [1.0 0.0 0.0 0.0 22.0 30000.0]\n",
      " [0.0 0.0 1.0 0.0 35.0 43000.0]\n",
      " [0.0 0.0 0.0 1.0 34.0 44000.0]\n",
      " [0.0 0.0 0.0 1.0 33.0 48000.0]\n",
      " [0.0 0.0 1.0 0.0 29.0 77000.0]\n",
      " [0.0 0.0 0.0 1.0 35.95238095238095 57000.0]\n",
      " [1.0 0.0 0.0 0.0 44.0 48000.0]\n",
      " [1.0 0.0 0.0 0.0 37.0 23000.0]\n",
      " [0.0 1.0 0.0 0.0 45.0 50000.0]\n",
      " [0.0 0.0 1.0 0.0 30.0 30000.0]\n",
      " [0.0 0.0 1.0 0.0 29.0 15000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Handling Categorical Data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('enconder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1801b1",
   "metadata": {},
   "source": [
    "In the ColumnTransformer class, for the argument ‘transformers’, we have a list containing a tuple as the parameter. The first item ‘encoder’ is the type of transformation we want. ‘OneHotEncoder()’ is the class that will handle the transformation. ‘[0]’ is the index of the column we want to encode. If we have multiple columns to transform, we can put them in the list. In this case, we only have one column with index 0, so it is only 0 that is in the list. The remainder=’passthrough’ means we want to leave the other columns the way they are without transforming them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebbb55a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No'\n",
      " 'Yes' 'Yes' 'Yes' 'Yes' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7df6f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28378a",
   "metadata": {},
   "source": [
    "### Splitting the Dataset\n",
    "\n",
    "Splitting our dataset into training & test set is another important step in data preprocessing. We will use part of the dataset to train the model. The other part of the dataset will be used to evaluate our model, to see how it performs on new data that it hasn’t seen before. We will do the split in the 80:20 ratio. 80% of the dataset will be used for training, while 20% will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbc4727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into Training and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2                                                , random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962099b",
   "metadata": {},
   "source": [
    "For the train_test_split function, the argument X is our features (independent variable). The argument y is our target variable,\n",
    "‘test_size=0.2’ means 20% of the dataset will be used as the test set. The random_state sets a seed to the random generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4bde8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 0.0 29.0 77000.0]\n",
      " [0.0 0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 0.0 22.0 30000.0]\n",
      " [0.0 1.0 0.0 0.0 50.0 83000.0]\n",
      " [0.0 0.0 1.0 0.0 18.0 15000.0]\n",
      " [1.0 0.0 0.0 0.0 37.0 67000.0]\n",
      " [0.0 1.0 0.0 0.0 40.0 50636.36363636364]\n",
      " [0.0 0.0 0.0 1.0 35.95238095238095 57000.0]\n",
      " [0.0 0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 0.0 1.0 35.95238095238095 52000.0]\n",
      " [1.0 0.0 0.0 0.0 37.0 23000.0]\n",
      " [1.0 0.0 0.0 0.0 44.0 48000.0]\n",
      " [0.0 0.0 1.0 0.0 50.0 60000.0]\n",
      " [0.0 0.0 1.0 0.0 29.0 15000.0]\n",
      " [0.0 0.0 1.0 0.0 35.0 43000.0]\n",
      " [0.0 0.0 0.0 1.0 33.0 48000.0]\n",
      " [1.0 0.0 0.0 0.0 48.0 79000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42f7d95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 0.0 45.0 50000.0]\n",
      " [1.0 0.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 0.0 30.0 30000.0]\n",
      " [1.0 0.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 0.0 1.0 34.0 44000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e1d4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3167f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca977711",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "This is the final step of data preprocessing. Feature scaling puts all our data in the same range and on the same scale. We do not want any feature of our dataset to dominate another feature. We don’t have to apply feature scaling to all datasets, especially if the features of that dataset are already within the same range. We could apply normalization or standardization to our dataset. The formula is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53618f27",
   "metadata": {},
   "source": [
    "$x = \\frac{x - mean(x)}{standard Deviation(x)}$; $x = \\frac{x - min(x)}{max(x) - min(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c930e37",
   "metadata": {},
   "source": [
    "Standardization puts all the values between the range of -3 and 3. But normalization will always give you positive values between the range of 0 and 1.\n",
    "We will apply standardization. We will use the StandardScaler class from the preprocessing module of the sklearn library. We won’t apply feature scaling to the one-hot encoded columns (dummy variables). We don’t want to change the interpretation of those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59379768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 4:] = sc.fit_transform(X_train[:, 4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087a2e9",
   "metadata": {},
   "source": [
    "The .fit() method of the StandardScaler() class will just calculate the mean and standard deviation for X_train, while the .transform() method will transform the values with the formula above. We can do the fit and transform in one line of code by using the .fit_transform() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "546f50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 0.0 -0.746521345589145 1.351588046193331]\n",
      " [0.0 0.0 0.0 1.0 0.28796566772827725 0.5327257531467691]\n",
      " [1.0 0.0 0.0 0.0 -1.55112235594714 -1.0538199396309444]\n",
      " [0.0 1.0 0.0 0.0 1.6672816854848402 1.6586614060857916]\n",
      " [0.0 0.0 1.0 0.0 -2.0108943618659945 -1.8215033393620963]\n",
      " [1.0 0.0 0.0 0.0 0.1730226662485637 0.8397991130392297]\n",
      " [0.0 1.0 0.0 0.0 0.5178516706877044 0.0023263133325189464]\n",
      " [0.0 0.0 0.0 1.0 0.05260618850791099 0.3280101798851286]\n",
      " [0.0 0.0 0.0 1.0 -0.9764073485485721 -0.13259985995356244]\n",
      " [0.0 1.0 0.0 0.0 -0.6315783441094314 0.17447349993889827]\n",
      " [0.0 0.0 0.0 1.0 0.05260618850791099 0.07211571330807803]\n",
      " [1.0 0.0 0.0 0.0 0.1730226662485637 -1.4120721928388154]\n",
      " [1.0 0.0 0.0 0.0 0.9776236766065588 -0.13259985995356244]\n",
      " [0.0 0.0 1.0 0.0 1.6672816854848402 0.481546859831359]\n",
      " [0.0 0.0 1.0 0.0 -0.746521345589145 -1.8215033393620963]\n",
      " [0.0 0.0 1.0 0.0 -0.056863336710863466 -0.388494326530613]\n",
      " [0.0 0.0 0.0 1.0 -0.28674933967029065 -0.13259985995356244]\n",
      " [1.0 0.0 0.0 0.0 1.437395682525413 1.4539458328241512]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbbe10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 0.0 45.0 50000.0]\n",
      " [1.0 0.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 0.0 30.0 30000.0]\n",
      " [1.0 0.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 0.0 1.0 34.0 44000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd07ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 0.0 1.0925666780862724 -0.030242073322742206]\n",
      " [1.0 0.0 0.0 0.0 0.9776236766065588 1.0956935796162803]\n",
      " [0.0 0.0 1.0 0.0 -0.6315783441094314 -1.0538199396309444]\n",
      " [1.0 0.0 0.0 0.0 -0.056863336710863466 0.37918907320053874]\n",
      " [0.0 0.0 0.0 1.0 -0.17180633819057706 -0.3373154332152029]]\n"
     ]
    }
   ],
   "source": [
    "X_test[:, 4:] = sc.transform(X_test[:, 4:])\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af135c",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Before we can train a Machine Learning model, we need to clean our data.\n",
    "If we don’t clean our dataset, we will run into some problems during training. We need to handle missing values, encode categorical variables, and sometimes apply feature scaling to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a946c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
